# 方案一（DINOGuidedRestormer）测试路线

> 基于实验11-14的结果分析，制定后续优化方向

## 当前最佳结果

| 实验 | 配置要点 | 最佳PSNR | 问题 |
|------|----------|----------|------|
| 12 | SFT + 300k + mixup | **22.87** | 90k后严重过拟合 |
| 13 | SFT + EMA + 80k | 21.94 | 稳定但峰值较低 |
| 14 | CrossAttn + EMA | 21.97 | 与SFT相近，无优势 |

**核心矛盾**: 长训练能达到更高峰值，但容易过拟合；短训练稳定但峰值受限。

---

## 第一阶段：抗过拟合优化（实验15-17）

### 实验15: EMA + 更长训练 + 强正则化
**目标**: 结合实验12的长训练和实验13的EMA稳定性

```yaml
name: 15_LowLight_DINORestormer_192_2_150k_sft_ema_reg
datasets:
  train:
    gt_size: 192
    batch_size_per_gpu: 2
    # 增强数据增强
    use_hflip: true
    use_rot: true
    mixup: true
    mixup_alpha: 0.2
    cutmix: true
    cutmix_alpha: 1.0

network_g:
  type: DINOGuidedRestormer
  dino_gamma: 0.35

train:
  total_iter: 150000
  warmup_iter: 3000
  ema_decay: 0.999
  
  # 损失权重（降低感知损失防止过拟合）
  pixel_opt:
    loss_weight: 1.0
  ssim_opt:
    loss_weight: 0.6
  perceptual_opt:
    loss_weight: 0.02  # 从0.03降低
  semantic_opt:
    loss_weight: 0.01

  scheduler:
    type: CosineAnnealingRestartCyclicLR
    periods: [50000, 100000]
    restart_weights: [1, 0.5]
    eta_mins: [0.0003, 0.000001]

val:
  val_freq: 2000
  save_best: true
  early_stop_patience: 20000  # 20k iter无提升则停止
```

**预期**: PSNR 22.5+ 且训练稳定

---

### 实验16: 学习率衰减策略优化
**目标**: 在峰值附近（60k-90k）大幅降低学习率

```yaml
name: 16_LowLight_DINORestormer_192_2_120k_sft_ema_lrdecay

train:
  total_iter: 120000
  warmup_iter: 2000
  ema_decay: 0.999
  
  scheduler:
    type: CosineAnnealingRestartCyclicLR
    periods: [60000, 60000]
    restart_weights: [1, 0.1]  # 60k后lr降到1/10
    eta_mins: [0.0003, 0.00001]
```

**预期**: 在60k-90k区间保持高PSNR，避免后期震荡

---

### 实验17: Dropout正则化
**目标**: 在网络中加入Dropout防止过拟合

```yaml
name: 17_LowLight_DINORestormer_192_2_100k_sft_ema_dropout

network_g:
  type: DINOGuidedRestormer
  dino_gamma: 0.35
  dropout: 0.1  # 需要修改arch支持
  drop_path: 0.1

train:
  total_iter: 100000
  ema_decay: 0.999
```

**预期**: 训练更稳定，泛化能力更强

---

## 第二阶段：DINO特征优化（实验18-19）

### 实验18: 更小的dino_gamma
**目标**: 降低DINO特征权重，让Restormer主导恢复

```yaml
name: 18_LowLight_DINORestormer_192_2_100k_sft_ema_lowgamma

network_g:
  type: DINOGuidedRestormer
  dino_gamma: 0.2  # 从0.35降低到0.2

train:
  total_iter: 100000
  ema_decay: 0.999
```

**预期**: 如果DINO特征引入噪声，降低gamma可能提升性能

---

### 实验19: 可学习的dino_gamma
**目标**: 让网络自动学习最优的DINO特征融合权重

```yaml
name: 19_LowLight_DINORestormer_192_2_100k_sft_ema_learngamma

network_g:
  type: DINOGuidedRestormer
  dino_gamma: 0.35
  learnable_gamma: true  # 需要修改arch支持
  gamma_init: 0.35

train:
  total_iter: 100000
  ema_decay: 0.999
```

**预期**: 网络自适应调整DINO特征权重

---

## 第三阶段：损失函数优化（实验20）

### 实验20: 调整损失权重组合
**目标**: 寻找最优损失权重配比

```yaml
name: 20_LowLight_DINORestormer_192_2_100k_sft_ema_lossopt

train:
  # 方案A: 强调SSIM
  pixel_opt:
    loss_weight: 1.0
  ssim_opt:
    loss_weight: 1.0  # 提高
  perceptual_opt:
    loss_weight: 0.01  # 降低
  semantic_opt:
    loss_weight: 0.005  # 降低
```

---

## 实验优先级排序

| 优先级 | 实验 | 理由 |
|--------|------|------|
| ⭐⭐⭐ | 15 | 最有可能突破22.87，结合长训练+EMA+强正则 |
| ⭐⭐⭐ | 16 | 学习率策略优化，低成本高收益 |
| ⭐⭐ | 18 | 验证DINO特征是否过强 |
| ⭐⭐ | 17 | Dropout正则化，需要修改代码 |
| ⭐ | 19 | 可学习gamma，需要修改代码 |
| ⭐ | 20 | 损失权重微调，收益可能有限 |

---

## 成功标准

- **短期目标**: PSNR ≥ 22.5 且训练稳定（无明显过拟合）
- **中期目标**: PSNR ≥ 23.0
- **理想目标**: PSNR ≥ 23.5，接近SOTA水平

---

## 注意事项

1. 每个实验运行前确保 `val_freq=2000`，便于观察过拟合趋势
2. 使用 `save_best=true` 自动保存最佳模型
3. 设置 `early_stop_patience=15000-20000`，避免浪费算力
4. 实验15优先运行，根据结果调整后续实验参数
