# DINOv3 + Restormer 低光照增强 总实验路线

## 实验概览

本项目探索三种 DINOv3 与 Restormer 的集成方案，用于低光照图像增强 (LLIE) 任务：

| 方案 | 架构名称 | 核心思路 | 复杂度 | 显存需求 |
|------|---------|---------|--------|---------|
| 基线 | Restormer | 原始 Restormer，无 DINO | 低 | ~4-6 GB |
| 方案一 | DINOGuidedRestormer | DINO 特征注入 Latent 层 | 中 | ~8-10 GB |
| 方案二 | MultiScaleDINOGuidedRestormer | 多尺度 FPN 融合 | 中高 | ~10-16 GB |
| 方案三 | DINOEncoderDecoder | DINO 作为唯一编码器 | 高 | ~6-14 GB |

---

## 第一阶段：基线建立 (Week 1)

### 目标
建立各方案的基线性能，确定后续实验的参考点。

### 实验列表

| 序号 | 实验名称 | 配置文件 | 预计时间 | 优先级 |
|-----|---------|---------|---------|-------|
| 0.1 | 原始 Restormer 基线 | `LowLight_Restormer.yml` | 10-12h | ⭐⭐⭐ |
| 1.1 | 方案一 Latent 引导 | `LowLight_DINORestormer.yml` | 10-12h | ⭐⭐⭐ |
| 2.1 | 方案二 FPN 融合 | `LowLight_DINORestormer_192_2_80k_fpn.yml` | 8-10h | ⭐⭐⭐ |
| 3.1 | 方案三 DINO Encoder | `LowLight_DINOEncoderDecoder.yml` | 8-10h | ⭐⭐⭐ |

### 运行命令

```bash
# 0.1 原始 Restormer 基线
python basicsr/train.py -opt LLIE/Options/LowLight_Restormer.yml

# 1.1 方案一 Latent 引导
python basicsr/train.py -opt LLIE/Options/LowLight_DINORestormer.yml

# 2.1 方案二 FPN 融合
python basicsr/train.py -opt LLIE/Options/LowLight_DINORestormer_192_2_80k_fpn.yml

# 3.1 方案三 DINO Encoder
python basicsr/train.py -opt LLIE/Options/LowLight_DINOEncoderDecoder.yml
```

### 基线结果记录

| 方案 | PSNR ↑ | SSIM ↑ | LPIPS ↓ | NIQE ↓ | 训练时间 | 显存 |
|-----|--------|--------|---------|--------|---------|------|
| 基线 Restormer | | | | | | |
| 方案一 | | | | | | |
| 方案二 | | | | | | |
| 方案三 | | | | | | |

---

## 第二阶段：超参数调优 (Week 2)

### 目标
针对各方案进行关键超参数调优，找到最优配置。

### 2.1 Gamma 敏感性测试 (所有方案)

Gamma 校正是低光照图像预处理的关键参数，影响 DINO 特征提取质量。

| 方案 | Gamma 测试值 | 方法 |
|-----|-------------|------|
| 方案一 | [0.30, 0.35, 0.40, 0.45] | 20k iter 快速对比 |
| 方案二 | [0.30, 0.35, 0.40, 0.45] | 20k iter 快速对比 |
| 方案三 | [0.30, 0.35, 0.40, 0.45, 0.50] | 20k iter 快速对比 |

### 2.2 方案特定调优

#### 方案一：融合方式对比
```
实验 1.2: SFT vs Cross-Attention
├── SFT: fusion_type=sft (默认)
├── CrossAttn: fusion_type=cross_attention
└── 配置: LowLight_DINORestormer_192_2_80k_crossattn.yml
```

#### 方案二：注入层级消融
```
实验 2.2: 注入层级对比
├── all: 全部层级注入 (默认)
├── latent_only: 仅 Latent 层
├── encoder_only: 仅 Encoder 层
└── 目标: 验证多尺度融合的必要性
```

#### 方案三：LoRA 微调
```
实验 3.2: LoRA 微调
├── 配置: LowLight_DINOEncoderDecoder_LoRA.yml
├── 测试: lora_r = [8, 16, 32]
└── 目标: 验证 LoRA 是否提升效果
```

### 超参数调优结果记录

| 方案 | 参数 | 测试值 | 最优值 | PSNR 提升 |
|-----|------|-------|-------|----------|
| 方案一 | gamma | [0.30-0.45] | | |
| 方案一 | fusion_type | [sft, cross_attention] | | |
| 方案二 | gamma | [0.30-0.45] | | |
| 方案二 | inject_levels | [all, latent, encoder] | | |
| 方案三 | gamma | [0.30-0.50] | | |
| 方案三 | lora_r | [8, 16, 32] | | |

---

## 第三阶段：消融实验 (Week 3)

### 目标
验证各组件的贡献，理解模型设计的有效性。

### 3.1 通用消融实验

| 实验 | 对比项 | 目标 |
|-----|-------|------|
| 块效应处理 | use_boundary_blend = [true, false] | 验证 PatchBoundaryBlender 作用 |
| 语义损失 | lambda_sem = [0, 0.01, 0.02, 0.05] | 验证 DINO 语义损失贡献 |
| 感知损失 | lambda_per = [0, 0.02, 0.05, 0.1] | 验证 VGG 感知损失贡献 |

### 3.2 方案特定消融

#### 方案二：提取层消融
```
dino_extract_layers 对比:
├── [12]: 仅深层语义
├── [8, 12]: 中层 + 深层
├── [4, 8, 12]: 全部层级 (默认)
└── [4, 12]: 浅层 + 深层 (跳过中层)
```

#### 方案三：解码器消融
```
hidden_dims 对比:
├── [256, 128, 64, 32]: 轻量解码器
├── [384, 192, 96, 48]: 标准解码器 (默认)
├── [512, 256, 128, 64]: 大容量解码器
```

### 消融实验结果记录

| 消融项 | 方案 | 变体 | PSNR | SSIM | 结论 |
|-------|-----|------|------|------|------|
| 块效应 | 方案三 | blend=false | | | |
| 语义损失 | 全部 | sem=0 | | | |
| 提取层 | 方案二 | [12] only | | | |
| 解码器 | 方案三 | 轻量 | | | |

---

## 第四阶段：最终对比与分析 (Week 4)

### 目标
使用各方案的最优配置进行最终对比，得出结论。

### 4.1 最终对比实验

使用各方案调优后的最优配置，在相同条件下进行完整训练：

| 方案 | 最优配置 | 训练迭代 |
|-----|---------|---------|
| 基线 | `LowLight_Restormer.yml` | 300k |
| 方案一 | 最优 gamma + 最优融合方式 | 80k |
| 方案二 | 最优 gamma + 最优注入层级 | 80k |
| 方案三 | 最优 gamma + LoRA (如有效) | 80k |

### 4.2 评估指标

```bash
# 有参考指标 (PSNR, SSIM, LPIPS)
python LLIE/metrics_cal.py --dirA ./ground_truth --dirB ./enhanced --use_gpu

# 无参考指标 (NIQE)
python LLIE/unsupervised_metrics_cal.py --dir ./enhanced --use_gpu
```

### 4.3 最终结果汇总

| 方案 | PSNR ↑ | SSIM ↑ | LPIPS ↓ | NIQE ↓ | 参数量 | 推理时间 | 显存 |
|-----|--------|--------|---------|--------|-------|---------|------|
| 基线 Restormer | | | | | ~26M | | |
| 方案一 (最优) | | | | | | | |
| 方案二 (最优) | | | | | | | |
| 方案三 (最优) | | | | | | | |

---

## 实验时间规划

```
Week 1: 基线建立
├── Day 1-2: 原始 Restormer 基线
├── Day 3-4: 方案一基线
├── Day 5-6: 方案二基线
└── Day 7: 方案三基线

Week 2: 超参数调优
├── Day 1-2: Gamma 敏感性测试 (所有方案)
├── Day 3-4: 方案一融合方式对比
├── Day 5-6: 方案二注入层级消融
└── Day 7: 方案三 LoRA 实验

Week 3: 消融实验
├── Day 1-2: 块效应处理消融
├── Day 3-4: 损失函数消融
├── Day 5-6: 方案特定消融
└── Day 7: 结果整理

Week 4: 最终对比
├── Day 1-3: 最优配置完整训练
├── Day 4-5: 全面评估
├── Day 6-7: 结果分析与报告
```

---

## 配置文件索引

### 基线
- `LLIE/Options/LowLight_Restormer.yml` - 原始 Restormer

### 方案一 (Latent 引导)
- `LLIE/Options/LowLight_DINORestormer.yml` - 基础配置
- `LLIE/Options/LowLight_DINORestormer_192_2_80k_crossattn.yml` - Cross-Attention 融合

### 方案二 (多尺度 FPN)
- `LLIE/Options/LowLight_DINORestormer_192_2_80k_fpn.yml` - FPN 融合基线

### 方案三 (DINO Encoder)
- `LLIE/Options/LowLight_DINOEncoderDecoder.yml` - 冻结 DINO 基线
- `LLIE/Options/LowLight_DINOEncoderDecoder_LoRA.yml` - LoRA 微调

---

## 注意事项

1. **显存管理**：如遇 OOM，优先降低 batch_size，其次降低 gt_size
2. **训练监控**：使用 TensorBoard 监控训练曲线，关注 loss 和 val_psnr
3. **Early Stopping**：所有配置已启用 early stopping，patience=25-30
4. **结果复现**：所有配置已设置 manual_seed=42
5. **模型保存**：checkpoint 每 10k iter 保存一次

---

## 快速开始

```bash
# 1. 安装依赖
pip install -r requirements.txt
python setup.py develop --no_cuda_ext

# 2. 验证环境
python scripts/verify_environment.py

# 3. 开始第一个实验 (原始 Restormer 基线)
python basicsr/train.py -opt LLIE/Options/LowLight_Restormer.yml

# 4. 查看训练日志
tensorboard --logdir experiments/
```
